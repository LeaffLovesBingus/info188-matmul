# info188-matmul

## Introducci贸n

###### Integrantes:
- Eduardo Montecinos
- Crist贸bal Silva
- Diego Soto
- Mat铆as Soto
- Mat铆as Toledo

La multiplicaci贸n de matrices es una operaci贸n fundamental en la computaci贸n, como se nos ha mencionado en clases, para la simulaci贸n f铆sica y el entrenamiento de redes neuronales. Al tratarse de una operaci贸n con complejidad secuencial de orden c煤bico, la manera en que se implementa puede tener un impacto significativo en el rendimiento y eficiencia de los sistemas, con el riesgo de que se dispare el runtime en funci贸n del tama帽o de las entradas. Por ello, resulta crucial explorar opciones de paralelizaci贸n para reducir el tiempo de c贸mputo excesivo.

En esta tarea se implement贸 la multiplicaci贸n de matrices con diferentes aplicaciones de procesamiento en paralelo:
1. Paralelismo en CPU 
2. Paralelismo en GPU b谩sico (con el approach tratado en clases) 
3. Paralelismo en GPU con **memoria compartida** 
4. Paralelismo en GPU con **tensor cores** 

El paralelismo en CPU fue programado con OpenMP (`#pragma omp parallel for`), mientras que las otras tres opciones se trabajaron con CUDA (NVIDIA). Los cuatro enfoques se encuentran en el mismo archivo [`main.cu`](./main.cu), que se compila con `make` y se ejecuta como:
    ```bash
    ./prog <tama帽o matriz> <n煤mero de threads CPU> <opci贸n 1-4 de algoritmos>
    ```

Con el fin de evaluar el rendimiento de cada opci贸n, se realizaron pruebas utilizando diferentes tama帽os de entrada (matrices cuadradas `n*n`) y se midi贸 el tiempo de ejecuci贸n en cada caso. Con los tiempos medidos, tambi茅n se determin贸 el speedup/aceleraci贸n de las tres implementaciones en GPU con respecto al paralelismo en CPU.

---

## Resultados

![](./img/CPU.png)

![](./img/GPU.png)

![](./img/Speedup-GPU-vs-CPU.png)

## Hardware utilizado para los tests
### CPU
|Especificaciones CPU||
|-|-|
|Marca|AMD|
|Modelo|Ryzen 5 3600|
|Frecuencia|3.6 GHz|
|Frecuencia turbo|Hasta 4.2 GHz|
|N煤cleos|6|
|Hilos|12|
|Cache L1|64 KB (por n煤cleo)|
|Cache L2|512 KB (por n煤cleo)|
|Cache L3|32 MB (compartido)|

### RAM
|Especificaciones RAM||
|-|-|
|Capacidad|32 GB (_Dual channel, 4x8 GB_)|
|Tipo|DDR4|
|Frecuencia|3000 MHz|

### GPU
|Especificaciones GPU||
|-|-|
|Marca|NVIDIA|
|Modelo|RTX 2060 Super|
|Procesador gr谩fico|TU106|
|Arquitectura|_Turing_|
|Reloj base|1470 MHz|
|Reloj boost|1650 MHz|
|VRAM|8 GB|
|Tipo VRAM|GDDR6|
|Ancho de banda VRAM|448.0 GB/s|
|CUDA Cores|2176|
|Tensor Cores|272|
|Tensor Cores por SM|8|
|Rendimiento FP16 (half)|14.36 TFLOPS|
|Rendimiento FP32 (float)|7.181 TFLOPS|
|Rendimiento FP64 (double)|224.4 GFLOPS|
|Versi贸n CUDA|7.5|

---

## Explicaci贸n e interpretaci贸n

A partir de los experimentos realizados, se observa una diferencia de rendimiento sustancial entre la ejecuci贸n paralelizada en CPU y la ejecuci贸n con hilos en GPU.

### Salto de tiempos de ejecuci贸n CPU vs GPU

Como se evidencia en la tabla de resultados y en los gr谩ficos, el tiempo de ejecuci贸n en la CPU crece dr谩sticamente a medida que aumenta el tama帽o de la matriz (cuadrada `n*n`). En el primer gr谩fico se distingue que, al llegar a `n = 3072`, el runtime alcanza las centenas de segundos, mientras que en las tres implementaciones paralelizadas en GPU las curvas se mantienen considerablemente cercanas al eje de las abscisas (en esta escala gr谩fica resultan indistinguibles).

En el caso `n = 4096`, la implementaci贸n en CPU tard贸 **291.12 segundos**, mientras que la implementaci贸n b谩sica/directa en GPU tard贸 **0.29 segundos**. Este caso representa un speedup de aproximadamente **989x**. La brecha en runtime que se abre con este tama帽o de entrada se debe a que la CPU est谩 limitada por un n煤mero mucho menor de n煤cleos f铆sicos (6 n煤cleos, 12 hilos en el Ryzen 5 3600 utilizado).

---

## Referencias
#### Shared memory
- [Mutliplicaci贸n matrices memoria compartida](https://medium.com/@dhanushg295/mastering-cuda-matrix-multiplication-an-introduction-to-shared-memory-tile-memory-coalescing-and-d7979499b9c5)

#### Tensor cores
- [Documentaci贸n oficial de Nvidia sobre Tensor cores](https://developer.nvidia.com/blog/programming-tensor-cores-cuda-9/)
- [Blog explicativo sobre la programaci贸n sobre Tensor cores](https://leimao.github.io/blog/NVIDIA-Tensor-Core-Programming/)
- [Video explicativo sobre programaci贸n en Tensor cores](https://youtu.be/Yt1A-vaWTck?si=3m5EwRk-dz3hGI70)

#### Hardware
- [Especificaciones RTX 2060 Super](https://www.techpowerup.com/gpu-specs/geforce-rtx-2060-super.c3441)
- [Especificaciones Ryzen 5 3600](https://www.techpowerup.com/cpu-specs/ryzen-5-3600.c2132)
